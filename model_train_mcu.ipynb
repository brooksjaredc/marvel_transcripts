{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I wanted to see if I could train a model to recognize MCU movie transcripts from the transcripts of similar movies\n",
    "\n",
    "### The trained models did an ok job, not great. I could have done a better job at feature engineering and removing stop words. But what it seemed to struggle the most with was certain MCU movies that didn't have any of the other main characters from the Avengers, like 'Dr. Strange' and 'Captain Marvel', which is understandable, but I had somewhat hoped that the language in the transcripts would give enough of a signal. It seems like its mostly picking out the names of the most popular characters\n",
    "\n",
    "### I'm not too worried that the models didn't do great, I was just doing this for practice and for funzies.\n",
    "\n",
    "### This notebook isn't very well documented and explained, I'm pretty sure no one will see this or care, its just for me to return to in order to copy and paste code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_scripts_and_titles.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['scripts'],df['MCU'],random_state=131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'bat',\n",
       " 'clogged',\n",
       " 'disperses',\n",
       " 'forrest',\n",
       " 'imitative',\n",
       " 'mania',\n",
       " 'pair',\n",
       " 'releases',\n",
       " 'slogan',\n",
       " 'throne',\n",
       " 'wider']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<48x22553 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 102639 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['man' 'spider' 'new' 'black' 'they' 'one' 'nick' 'daisy' 'of' 'your']\n",
      "\n",
      "Largest Coefs: \n",
      "['it' 'he' 'on' 'in' 'steve' 'banner' 'up' 'as' 'scott' 'bruce']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5343"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['groggy' 'slumped' 'stomps' 'leadership' 'stroll' 'generating'\n",
      " 'collision' 'adjusts' 'sideways' 'shudders']\n",
      "\n",
      "Largest tfidf: \n",
      "['logan' 'peter' 'spider' 'the' 'scott' 'panther' 'tony' 'edward' 'blade'\n",
      " 'thor']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['spider' 'logan' 'man' 'edward' 'charles' 'swan' 'gwen' 'jacob' 'black'\n",
      " 'jean']\n",
      "\n",
      "Largest Coefs: \n",
      "['tony' 'thor' 'steve' 'stark' 'scott' 'peter' 'the' 'jane' 'rogers'\n",
      " 'challa']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21641"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,4)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['man' 'spider' 'spider man' 'black' 'new' 'they' 'but' 'one' 'your' 'of']\n",
      "\n",
      "Largest Coefs: \n",
      "['it' 'he' 'on' 'steve' 'scott' 'tony' 'ross' 'challa' 'in' 'rocket']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.400\n",
      "Precision: 1.000\n",
      "Accuracy: 0.812\n",
      "F1: 0.571\n",
      "[[11  0]\n",
      " [ 3  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, predictions)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, predictions)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, predictions)))\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52    0\n",
       "40    0\n",
       "45    0\n",
       "19    1\n",
       "10    0\n",
       "17    1\n",
       "6     1\n",
       "16    0\n",
       "38    0\n",
       "13    1\n",
       "39    0\n",
       "9     0\n",
       "62    0\n",
       "35    0\n",
       "36    0\n",
       "14    1\n",
       "Name: MCU, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "clfnb = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfnb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = clfnb.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.600\n",
      "Precision: 1.000\n",
      "Accuracy: 0.875\n",
      "F1: 0.750\n",
      "[[11  0]\n",
      " [ 2  3]]\n"
     ]
    }
   ],
   "source": [
    "print('Recall: {:.3f}'.format(recall_score(y_test, predictions)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, predictions)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, predictions)))\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clfsv = svm.SVC(kernel='rbf', C=0.001)\n",
    "clfnb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = clfnb.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.600\n",
      "Precision: 1.000\n",
      "Accuracy: 0.875\n",
      "F1: 0.750\n",
      "[[11  0]\n",
      " [ 2  3]]\n"
     ]
    }
   ],
   "source": [
    "print('Recall: {:.3f}'.format(recall_score(y_test, predictions)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, predictions)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, predictions)))\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21433"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "vect = TfidfVectorizer(min_df=5,max_df=0.5,ngram_range=(1,2)).fit(df['scripts'])\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorized = vect.transform(df['scripts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       1.         0.71428571 0.83333333 0.83333333 0.83333333\n",
      " 1.         0.83333333 0.83333333 0.83333333]\n",
      "0.8464285714285713\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clfsv = svm.SVC(kernel='linear', C=1.0)\n",
    "\n",
    "cv_scores = cross_val_score(clfsv, X_vectorized, df['MCU'], cv=10)\n",
    "\n",
    "print(cv_scores)\n",
    "print(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
